# BSD 3-Clause License
#
# Copyright (c) 2018, Pruthvi Kumar All rights reserved.
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
# following conditions are met:
#
# Redistributions of source code must retain the above copyright notice, this list of conditions and the following
# disclaimer.
#
# Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following
# disclaimer in the documentation and/or other materials provided with the distribution.
#
# Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products
# derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
# INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

__author__ = "Pruthvi Kumar, pruthvikumar.123@gmail.com"
__copyright__ = "Copyright (C) 2018 Pruthvi Kumar | http://www.apricity.co.in"
__license__ = "BSD 3-Clause License"
__version__ = "1.0"

from gevent import monkey
monkey.patch_socket()
monkey.patch_ssl()
# ensure monkey patching for gevents to work their charm.
# remember - monkey patching is a necessary evil here.
import gevent
import time

class Parallel_Programming:

    def __init__(self):
        super(Parallel_Programming, self).__init__()

    def __generate_multiple_threads(self, associated_function, *args):
        """
        Parallel Programming is Tricky. Used well, reaps many benefits; if otherwise, it will be a nightmare.
        Multiple threading is advised for IO heavy ops (Like making multiple API calls concurrently). If what you want
        is not IO heavy but CPU heavy, consider multi processing instead. Multi Threading is not best suited or CPU
        intense operations.

        :param associated_function: function that the greenlet is supposed to execute.
        :param args: Dynamic argument list. Will resolve to a tuple.
        :return: a greenlet.
        """

        return gevent.spawn(associated_function, *args)

    def __execute_multiple_threads(self, greenlets_pool, time_since_pool = None):
        """

        :param greenlets_pool: a list of greenlets
        :param time_since_pool: time.time() value. This essentially must be the time when pool was generated by
        generate_multiple_threads
        :return: results in dictionary suggesting time of execution. StartTime, endTime-StartTime
        """

        start_time = time.time()
        gevent.joinall(greenlets_pool)
        end_time = time.time()
        results = list(map(lambda g: g.value, greenlets_pool))

        return {
            'execution_time': end_time - start_time,
            'execution_time_since_pool_gen': None if time_since_pool is None else end_time - time_since_pool,
            'thread_pool_results': results
        }

    #########################################################################################################
    # Multi Threading Wrapper. [PS: Use Multi Threading only on IO heavy ops; Not CPU intense]
    #########################################################################################################
    def concurrency_wrapper(self, type, target_function, *args):
        """
         Multi-threading functionality available should this MIC stack need it.
         self.generate_multiple_threads: Method to generate multiple threads and create a thread pool.
         self.execute_multiple_threads: Method to concurrently execute threads in a threadpool.

        :param type: Valid Options: 'http', 'non-http',
        :param target_function: Target function that threads should execute (This function should be in scope)
        :param args: Arguments expected by target function. If type=='http', *args[0] must be a list of URLS.
        :return: Results respective to type of operation specified.
        """
        from configuration import ProtonConfig
        from nucleus.generics.log_utilities import LogUtilities

        logger = LogUtilities().get_logger(log_file_name='parallel_programming_logs',
                                           log_file_path='{}/trace/parallel_programming_logs.log'.format(
                                               ProtonConfig.ROOT_DIR))

        def __http_calls_resolver(target_function, args):
            """

            :param target_function: Target function that threads should execute (This function should be in scope)
            :param args:[List] Arguments expected by target function. For HTTP Calls, args[0] = A list of urls to
            perform HTTP Operation.
            :return:[List] Thread Pool Results
            """
            # TODO: Validate input parameters to contain expected; fail gracefully if not.

            try:
                _args = list(args)
                urls = _args[0]
                _args.pop(0)

                # Step 1: Create number of threads required.
                threads_pool = list(map(lambda url: self.__generate_multiple_threads(target_function, url, _args),
                                        urls))
                time_after_pool = time.time()
                logger.info('[Parallel Programming] - Threads pool created with {} threads to resolve {} '
                            'method concurrently'.format(len(urls), target_function))

                # Step 2: Execute threads concurrently.
                thread_pool_results = self.__execute_multiple_threads(threads_pool, time_after_pool)
                logger.info(
                    '[Parallel Programming] - {} threads executed concurrently. Operation was completed in '
                    '{} seconds and took {} seconds since thread pool was '
                    'spawned.'.format(len(urls), thread_pool_results['execution_time'],
                                      thread_pool_results['execution_time_since_pool_gen']))

                return thread_pool_results

            except Exception as e:
                logger.exception(
                    '[Parallel Programming] - Error completing HTTP call resolver. Stack trace to follow')
                logger.exception(str(e))

        def __non_http_resolver(target_function, args):
            """

            :param target_function: Target function that threads should execute (This function should be in scope)
            :param args:[List] Arguments expected by target function.
            :return:[List] Thread Pool Results.
            """

            try:
                # Step 1: Create number of threads required.
                threads_pool = list(map(lambda arg: self.__generate_multiple_threads(target_function, arg), args))
                time_after_pool = time.time()
                logger.info('[Parallel Programming] - Threads pool created with {} threads to resolve {} '
                            'method concurrently'.format(len(args), target_function))

                # Step 2: Execute threads concurrently.
                thread_pool_results = self.__execute_multiple_threads(threads_pool, time_after_pool)
                logger.info(
                    '[Parallel Programming] - {} threads executed concurrently. Operation was completed in '
                    '{} seconds and took {} seconds since thread pool was '
                    'spawned.'.format(len(args), thread_pool_results['execution_time'],
                                      thread_pool_results['execution_time_since_pool_gen']))

                return thread_pool_results

            except Exception as e:
                logger.exception(
                    '[Parallel Programming] - Error completing Non-HTTP resolver. Stack trace to follow')
                logger.exception(str(e))

        __map_type = {'http': __http_calls_resolver, 'non-http': __non_http_resolver}

        return __map_type[type](target_function, args)
